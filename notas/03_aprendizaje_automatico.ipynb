{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento digital de imágenes con aprendizaje automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje automático (*Machine Learning*) es una disciplina que se enfoca\n",
    "en el desarrollo de algoritmos que permiten generalizar comportamientos a partir\n",
    "de muchos ejemplos.\n",
    "Combina conceptos de matemáticas, estadística y computación; y se puede dividir\n",
    "en dos grandes categorías: aprendizaje supervisado y no supervisado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. El problema del agrupamiento y la posterización de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "datos_iris = datasets.load_iris()\n",
    "datos_iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datos_iris[\"data\"], datos_iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices = random.sample(range(len(X)), k=3)\n",
    "centroides = X[indices]\n",
    "centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def distancia(vec_x, vec_y):\n",
    "    return math.sqrt(sum((vec_x - vec_y)**2))\n",
    "\n",
    "def encontar_centroide(X, centroides):\n",
    "    def distancia_a_centroide(i):\n",
    "        return distancia(vec_x, centroides[i])\n",
    "    \n",
    "    indices = range(len(centroides))\n",
    "    etiquetas = [None]*len(X)\n",
    "    for i, vec_x in enumerate(X):\n",
    "        etiquetas[i] = min(indices, key=distancia_a_centroide)\n",
    "    \n",
    "    return etiquetas\n",
    "\n",
    "def centro_de_masa(X):\n",
    "    return sum(X)/len(X)\n",
    "\n",
    "def inercia(X, centroides):\n",
    "    etiquetas = np.array(encontar_centroide(X, centroides))\n",
    "    total = 0.0\n",
    "    for i in range(len(centroides)):\n",
    "        seleccion = X[etiquetas == i]\n",
    "        distancias = [distancia(vec_x, centroides[i]) for vec_x in seleccion]\n",
    "        total += sum(d**2 for d in distancias)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = random.sample(range(len(X)), k=3)\n",
    "centroides = X[indices]\n",
    "print(\"Inercia inicial:\", inercia(X, centroides))\n",
    "\n",
    "for t in range(15):\n",
    "    etiquetas = np.array(encontar_centroide(X, centroides))\n",
    "    for i in range(len(centroides)):\n",
    "        seleccion = X[etiquetas == i]\n",
    "        centroides[i] = centro_de_masa(seleccion)\n",
    "    print(f\"Inercia al tiempo {t}: {inercia(X, centroides)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# PASO 1: Definir el modelo\n",
    "modelo = KMeans(n_clusters=3)\n",
    "# PASO 2: Realizar entrenamiento\n",
    "modelo.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "from materiales.sipi import ejemplo_sipi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ski.io.imread(\"sipi/misc/4.2.06.tiff\")\n",
    "img[0, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alto, ancho, canales = img.shape\n",
    "X = img.reshape((alto*ancho, canales))\n",
    "\n",
    "modelo = KMeans(8)\n",
    "modelo.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster = np.array([modelo.cluster_centers_[etiqueta] for etiqueta in modelo.labels_])\n",
    "poster = poster.reshape((alto, ancho, canales))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ski.io.imshow(poster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. El algoritmo SIFT para la detección de puntos de interés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos dos fotografías acerca del mismo objeto y son\n",
    "relativamente similares, como por ejemplo, dos fotografías de una estatua\n",
    "famosa. Si las dos imágenes son sufiencientemente similares salvo rotación,\n",
    "acercamiento o cambio de iluminación, entonces sería posible encontrar\n",
    "correspondencias entre los puntos de interés de ambas imágenes.\n",
    "Eso es exactamente lo que hace el algoritmo SIFT (*Scale-Invariant Feature\n",
    "Transform*), que es un algoritmo de visión por computadora que permite\n",
    "detectar y describir puntos de interés en una imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Aplicación del desenfoque gaussiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera etapa del algoritmo SIFT consiste en aplicar un desenfoque gaussiano\n",
    "iterativo a la imagen original.\n",
    "El desenfoque gaussiano es un filtro que se utiliza para atenuar el ruido de\n",
    "alta frecuencia en una imagen.\n",
    "Para ello utilizamos la convolución de la imagen original con un kernel\n",
    "gaussiano, es decir, con una ventana de valores que siguen una distribución\n",
    "gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "from skimage import data, filters\n",
    "\n",
    "\n",
    "def kernel_gaussiano(sigma, tamano = None):\n",
    "    if tamano is None:\n",
    "        tamano = int(6*sigma)\n",
    "    x = np.arange(-tamano // 2, tamano // 2 + 1)\n",
    "    y = np.arange(-tamano // 2, tamano // 2 + 1)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    result = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    # Normalizar para que la suma sea 1\n",
    "    return result / result.sum()\n",
    "\n",
    "def mostrar_kernel_gaussiano(sigma):\n",
    "    kernel = kernel_gaussiano(sigma)\n",
    "    plt.imshow(kernel, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "mostrar_kernel_gaussiano(1.618)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "\n",
    "# Graficar en 3D la ventana de un kernel gaussiano\n",
    "kernel = kernel_gaussiano(1.618)\n",
    "# Usar la función meshgrid para obtener las coordenadas de los puntos\n",
    "x = np.arange(kernel.shape[0])\n",
    "y = np.arange(kernel.shape[1])\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "# Crear la figura\n",
    "fig = plotly.graph_objs.Figure(data=[\n",
    "    plotly.graph_objs.Surface(z=kernel, x=xx, y=yy)\n",
    "])\n",
    "# Mostrar la figura en Jupyter\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolucion(imagen, kernel):\n",
    "    return signal.convolve2d(imagen, kernel, mode=\"same\")\n",
    "\n",
    "\n",
    "def suavizar(imagen, sigma):\n",
    "    kernel = kernel_gaussiano(sigma)\n",
    "    if len(imagen.shape) == 2:\n",
    "        return convolucion(imagen, kernel)\n",
    "    n_canales = imagen.shape[2]\n",
    "    imgs = [imagen[:, :, i] for i in range(n_canales)]\n",
    "    canales = [convolucion(imgs[i], kernel) for i in range(n_canales)]\n",
    "    return np.stack(canales, axis=2)\n",
    "\n",
    "\n",
    "def ejemplo_suavizado(img, s, sigma, k=3):\n",
    "    # Aplicar suavizado con s^1 sigma, s^2 sigma, ..., s^k sigma\n",
    "    fig, axs = plt.subplots(1, k, figsize=(20, 5))\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].set_title(\"Original\")\n",
    "    for i in range(1, k):\n",
    "        img_suave = suavizar(img, sigma * s**i)\n",
    "        axs[i].imshow(img_suave)\n",
    "        axs[i].axis(\"off\")\n",
    "        axs[i].set_title(f\"Suavizado {i}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "img = ski.img_as_float(data.chelsea())\n",
    "ejemplo_suavizado(img, 1.618, 1.618, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia de gaussianas, es decir, la resta de dos imágenes desenfocadas\n",
    "con diferentes valores de sigma, es un método útil para encontrar los bordes\n",
    "de los objetos en una imagen, ya que los bordes son precisamente las regiones\n",
    "de la imagen donde los valores de los píxeles cambian abruptamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferencia de gaussianas\n",
    "def diferencia_gaussianas(img, sigma1, sigma2):\n",
    "    suave1 = suavizar(img, sigma1)\n",
    "    suave2 = suavizar(img, sigma2)\n",
    "    return suave1 - suave2\n",
    "\n",
    "def ejemplo_diferencia_gaussianas(img, sigma1, sigma2):\n",
    "    dog = diferencia_gaussianas(img, sigma1, sigma2)\n",
    "    # Normalizar para mostrar\n",
    "    dog = (dog - dog.min()) / (dog.max() - dog.min())\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].set_title(\"Original\")\n",
    "    axs[1].imshow(dog, cmap=\"gray\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[1].set_title(\"Diferencia de gaussianas\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "img = ski.img_as_float(data.astronaut())\n",
    "ejemplo_diferencia_gaussianas(img, 1, 1.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apilar_dog(img, s, sigma, k):\n",
    "    # Aplicar suavizado con s^1 sigma, s^2 sigma, ..., s^k sigma\n",
    "    if len(img.shape) == 3:\n",
    "        # Convertir a escala de grises\n",
    "        img = ski.color.rgb2gray(img)\n",
    "    suves = [suavizar(img, sigma * s**i) for i in range(k)]\n",
    "    dogs = [suves[i] - suves[i+1] for i in range(k-1)]\n",
    "    # Apilar diferencias de gaussianas\n",
    "    return np.stack(dogs, axis=2)\n",
    "\n",
    "def ejemplo_apilar_dog(img, s, sigma, k):\n",
    "    dog = apilar_dog(img, s, sigma, k)\n",
    "    fig, axs = plt.subplots(1, k-1, figsize=(20, 5))\n",
    "    for i in range(k-1):\n",
    "        diff = dog[:, :, i]\n",
    "        # Normalizar\n",
    "        min_diff = np.min(diff)\n",
    "        diff = (diff - min_diff)/(np.max(diff) - min_diff)\n",
    "        axs[i].imshow(diff, cmap=\"gray\")\n",
    "        axs[i].axis(\"off\")\n",
    "        axs[i].set_title(f\"DOG {i+1}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "ejemplo_apilar_dog(img, 1.618, 1.618, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hola\"[0:3 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def encontrar_puntos(dogs):\n",
    "    # Convertir a valor absoluto el tensor dogs\n",
    "    dogs = np.abs(dogs)\n",
    "    alto, ancho, profundo = dogs.shape\n",
    "    resultado = set()\n",
    "    for i, j, k in itertools.product(range(alto), range(ancho), range(profundo)):\n",
    "        vecindad = dogs[\n",
    "            max(i - 1, 0) : min(i + 2, alto),\n",
    "            max(j - 1, 0) : min(j + 2, ancho),\n",
    "            max(k - 1, 0) : min(k + 2, profundo),\n",
    "        ]\n",
    "        max_vecindad = np.max(vecindad)\n",
    "        # Si el píxel dogs[i, j, k] es un máximo o mínimo local, se\n",
    "        # considera un punto de interés\n",
    "        if dogs[i, j, k] == max_vecindad:\n",
    "            resultado.add((i, j))\n",
    "        \n",
    "    return resultado\n",
    "\n",
    "def ejemplo_encontrar_puntos(img, s, sigma, k):\n",
    "    dogs = apilar_dog(img, s, sigma, k)\n",
    "    puntos = encontrar_puntos(dogs)\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    axs.imshow(img)\n",
    "    axs.axis(\"off\")\n",
    "    for i, j in puntos:\n",
    "        axs.plot(j, i, \"ro\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "ejemplo_encontrar_puntos(img, 1.618, 1.618, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import match_descriptors, plot_matches, SIFT\n",
    "\n",
    "img1 = rgb2gray(data.astronaut())\n",
    "img2 = transform.rotate(img1, 180)\n",
    "tform = transform.AffineTransform(scale=(1.3, 1.1), rotation=0.5, translation=(0, -200))\n",
    "img3 = transform.warp(img1, tform)\n",
    "\n",
    "descriptor_extractor = SIFT()\n",
    "\n",
    "descriptor_extractor.detect_and_extract(img1)\n",
    "keypoints1 = descriptor_extractor.keypoints\n",
    "descriptors1 = descriptor_extractor.descriptors\n",
    "\n",
    "descriptor_extractor.detect_and_extract(img2)\n",
    "keypoints2 = descriptor_extractor.keypoints\n",
    "descriptors2 = descriptor_extractor.descriptors\n",
    "\n",
    "descriptor_extractor.detect_and_extract(img3)\n",
    "keypoints3 = descriptor_extractor.keypoints\n",
    "descriptors3 = descriptor_extractor.descriptors\n",
    "\n",
    "matches12 = match_descriptors(\n",
    "    descriptors1, descriptors2, max_ratio=0.6, cross_check=True\n",
    ")\n",
    "matches13 = match_descriptors(\n",
    "    descriptors1, descriptors3, max_ratio=0.6, cross_check=True\n",
    ")\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(11, 8))\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "plot_matches(ax[0, 0], img1, img2, keypoints1, keypoints2, matches12)\n",
    "ax[0, 0].axis('off')\n",
    "ax[0, 0].set_title(\"Original Image vs. Flipped Image\\n\" \"(all keypoints and matches)\")\n",
    "\n",
    "plot_matches(ax[1, 0], img1, img3, keypoints1, keypoints3, matches13)\n",
    "ax[1, 0].axis('off')\n",
    "ax[1, 0].set_title(\n",
    "    \"Original Image vs. Transformed Image\\n\" \"(all keypoints and matches)\"\n",
    ")\n",
    "\n",
    "plot_matches(\n",
    "    ax[0, 1], img1, img2, keypoints1, keypoints2, matches12[::15], only_matches=True\n",
    ")\n",
    "ax[0, 1].axis('off')\n",
    "ax[0, 1].set_title(\n",
    "    \"Original Image vs. Flipped Image\\n\" \"(subset of matches for visibility)\"\n",
    ")\n",
    "\n",
    "plot_matches(\n",
    "    ax[1, 1], img1, img3, keypoints1, keypoints3, matches13[::15], only_matches=True\n",
    ")\n",
    "ax[1, 1].axis('off')\n",
    "ax[1, 1].set_title(\n",
    "    \"Original Image vs. Transformed Image\\n\" \"(subset of matches for visibility)\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
